# LLM Projects and Assignments – Manish Kanuri

This repository contains my academic and applied projects focused on **Large Language Models (LLMs)** and **Generative AI**.  
Each project demonstrates the implementation of modern NLP methods, fine-tuning techniques, and prompt engineering strategies using **Hugging Face Transformers**, **PyTorch**, and related frameworks.

---

## Project Portfolio

### GPT-2 From Scratch
**Description:** Implemented a miniature GPT-2 model entirely from first principles using PyTorch.  
**Highlights:**
- Built and trained a transformer architecture from scratch, including tokenization, attention, and positional embeddings.  
- Generated coherent text continuations and benchmarked against pre-trained GPT-2 small.  
**Files:**  
- `GPT2_From_Scratch_ManishKanuri.ipynb`  
- `GPT2_Project_Report_ManishKanuri.pdf`

---

### PA4 – Hugging Face Transformers (Fine-Tuning)
**Description:** Fine-tuned instruction models using **Parameter-Efficient Fine-Tuning (PEFT)** and **Hugging Face Transformers**.  
**Highlights:**
- Evaluated ROUGE metrics on summarization tasks.  
- Demonstrated consistent improvements through LoRA and instruction-tuning.  
- Focused on performance optimization and evaluation methodology.  
**Files:**  
- `LLM_PA4_Transformers_ManishKanuri.ipynb`  
- `LLM_PA4_Report_ManishKanuri.pdf`

---

### PA5 – Prompt Engineering
**Description:** Explored prompt engineering strategies to improve LLM response quality, reasoning, and consistency.  
**Highlights:**
- Implemented zero-shot, few-shot, and chain-of-thought prompting.  
- Measured impact on task-specific accuracy and coherence.  
- Applied temperature and context length adjustments for improved control.  
**Files:**  
- `PA5_Prompt_Engineering_ManishKanuri.ipynb`

---

### PA6 – PEFT and Model Evaluation
**Description:** Fine-tuned models using **PEFT (Parameter-Efficient Fine-Tuning)** and compared performance metrics before and after tuning.  
**Highlights:**
- Measured ROUGE improvements between base and fine-tuned models.  
- Analyzed trade-offs between model efficiency and output quality.  
**Files:**  
- `PA6_PEFT_ManishKanuri.ipynb`

---

## About
Created and maintained by **Manish Kanuri**  
M.S. in Data Science, Northeastern University (2024–2026)  
Email: kanuri.m@northeastern.edu | LinkedIn: [linkedin.com/in/ManishKanuri](https://www.linkedin.com/in/manish-kanuri/)
